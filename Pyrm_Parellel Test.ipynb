{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Tim/anaconda2/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization, Input\n",
    "from keras.layers import Conv2D, MaxPool2D\n",
    "from keras.models import Model\n",
    "from keras.datasets import cifar10\n",
    "from keras import regularizers\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "import numpy as np\n",
    "import weave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_schedule(epoch):\n",
    "    return (0.00100385 - 6.92308e-6*epoch)\n",
    "\n",
    "def straight_stack(x, num_filters, rep = 3, weight_decay = 1e-4, dropout_start = 0.2, dropout_add = .1):\n",
    "    for n in range(rep):\n",
    "        x = Conv2D((2**n)*num_filters, (3,3), padding='same', activation='elu', kernel_regularizer=regularizers.l2(weight_decay))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Conv2D((2**n)*num_filters, (3,3), padding='same', activation='elu', kernel_regularizer=regularizers.l2(weight_decay))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = MaxPool2D()(x)\n",
    "        x = Dropout(dropout_start+n*dropout_add)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 3, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "print(x_train.shape)\n",
    " \n",
    "#z-score\n",
    "mean = np.mean(x_train,axis=(0,1,2,3))\n",
    "std = np.std(x_train,axis=(0,1,2,3))\n",
    "x_train = (x_train-mean)/(std+1e-7)\n",
    "x_test = (x_test-mean)/(std+1e-7)\n",
    " \n",
    "num_classes = 10\n",
    "y_train = np_utils.to_categorical(y_train,num_classes)\n",
    "y_test = np_utils.to_categorical(y_test,num_classes)\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    )\n",
    "datagen.fit(x_train)\n",
    "\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "10/10 [==============================] - 24s 2s/step - loss: 3.5734 - acc: 0.1438 - val_loss: 2.7367 - val_acc: 0.1960\n",
      "10/10 [==============================] - 0s 11ms/step\n",
      "GPU settings allow for inf layers\n",
      "Minimum output size allow for 5 layers\n",
      "Number of layers 1\n",
      "First Layer Size: 1 (Number of Units)\n",
      "('Disjoint:', True)\n",
      "number of units 1\n",
      "number of devices 2\n",
      "number of inputs 2\n",
      "First Layer Output Size: 1 (Number of Tensors)\n",
      "Final Layer Size 1\n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 26s 3s/step - loss: 2.4022 - acc: 0.1141 - val_loss: 2.1916 - val_acc: 0.2220\n",
      "10/10 [==============================] - 0s 12ms/step\n",
      "GPU settings allow for inf layers\n",
      "Minimum output size allow for 5 layers\n",
      "Number of layers 2\n",
      "First Layer Size: 2 (Number of Units)\n",
      "('Disjoint:', True)\n",
      "number of units 2\n",
      "number of devices 4\n",
      "number of inputs 4\n",
      "First Layer Output Size: 2 (Number of Tensors)\n",
      "('Disjoint:', True)\n",
      "number of units 1\n",
      "number of devices 4\n",
      "number of inputs 2\n",
      "Final Layer Size 1\n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 36s 4s/step - loss: 2.3006 - acc: 0.1531 - val_loss: 2.2094 - val_acc: 0.2220\n",
      "10/10 [==============================] - 0s 14ms/step\n",
      "GPU settings allow for inf layers\n",
      "Minimum output size allow for 5 layers\n",
      "Number of layers 3\n",
      "First Layer Size: 4 (Number of Units)\n",
      "('Disjoint:', True)\n",
      "number of units 4\n",
      "number of devices 8\n",
      "number of inputs 8\n",
      "First Layer Output Size: 4 (Number of Tensors)\n",
      "('Disjoint:', True)\n",
      "number of units 2\n",
      "number of devices 8\n",
      "number of inputs 4\n",
      "('Disjoint:', True)\n",
      "number of units 1\n",
      "number of devices 8\n",
      "number of inputs 2\n",
      "Final Layer Size 1\n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 60s 6s/step - loss: 2.3060 - acc: 0.1375 - val_loss: 2.2491 - val_acc: 0.1620\n",
      "10/10 [==============================] - 0s 24ms/step\n",
      "GPU settings allow for inf layers\n",
      "Minimum output size allow for 5 layers\n",
      "Number of layers 4\n",
      "First Layer Size: 8 (Number of Units)\n",
      "('Disjoint:', True)\n",
      "number of units 8\n",
      "number of devices 16\n",
      "number of inputs 16\n",
      "First Layer Output Size: 8 (Number of Tensors)\n",
      "('Disjoint:', True)\n",
      "number of units 4\n",
      "number of devices 16\n",
      "number of inputs 8\n",
      "('Disjoint:', True)\n",
      "number of units 2\n",
      "number of devices 16\n",
      "number of inputs 4\n",
      "('Disjoint:', True)\n",
      "number of units 1\n",
      "number of devices 16\n",
      "number of inputs 2\n",
      "Final Layer Size 1\n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 110s 11s/step - loss: 2.3020 - acc: 0.1609 - val_loss: 2.2752 - val_acc: 0.1540\n",
      "10/10 [==============================] - 0s 28ms/step\n"
     ]
    }
   ],
   "source": [
    "viewer = keras.callbacks.TensorBoard(log_dir='./logs', \n",
    "                                     histogram_freq=0, \n",
    "                                     batch_size=batch_size, \n",
    "                                     write_graph=True)\n",
    "num_filters = 16\n",
    "num_val_test = 500\n",
    "epochs = 1\n",
    "model_details = {}\n",
    "for num_stack in [1, 2, 4, 8, 16]:\n",
    "    inputs = Input(shape=(3,32,32))\n",
    "    input_array = []\n",
    "    for stack in range(num_stack):\n",
    "        x = straight_stack(inputs, num_filters/num_stack)\n",
    "        input_array.append(x)\n",
    "    pyrm_layers = np.log2(num_stack)\n",
    "    if pyrm_layers > 0:\n",
    "        x = weave.pyrm_net(input_size=(4,4,128),\n",
    "                           n_layers = pyrm_layers,\n",
    "                           n_filters_start = 128,\n",
    "                           n_gpus = 1,\n",
    "                           inputs = input_array,\n",
    "                           r_filter = 1,\n",
    "                           r_combine= 1,\n",
    "                           min_dim = 2,\n",
    "                           max_pool_loc = 5,\n",
    "                           pure_combine = True,\n",
    "                           end_max_pool = False)\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    \n",
    "    predictions = Dense(num_classes, activation='softmax')(x)\n",
    "    model = Model(inputs=[inputs], outputs=predictions)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    #model.summary()\n",
    "    num_params = model.count_params()\n",
    "    \n",
    "    model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                    steps_per_epoch=10,#x_train.shape[0] // batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test[0:num_val_test],y_test[0:num_val_test]),\n",
    "                    callbacks=[LearningRateScheduler(lr_schedule), viewer])\n",
    "    model_details[num_stack] = (num_params, model.evaluate(x_test[0:10],y_test[0:10]))\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: (82778, [2.536757469177246, 0.10000000149011612]),\n",
       " 2: (94746, [1.9628959894180298, 0.5]),\n",
       " 4: (225498, [1.9888815879821777, 0.4000000059604645]),\n",
       " 8: (513786, [2.167442798614502, 0.20000000298023224]),\n",
       " 16: (1103754, [2.275731086730957, 0.0])}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_details\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
