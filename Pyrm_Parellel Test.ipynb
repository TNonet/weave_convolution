{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Tim/anaconda2/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization, Input\n",
    "from keras.layers import Conv2D, MaxPool2D\n",
    "from keras.models import Model\n",
    "from keras.datasets import cifar10\n",
    "from keras import regularizers\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "import numpy as np\n",
    "import weave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'channels_first'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.backend.image_data_format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_schedule(epoch):\n",
    "    return (0.00100 - 7e-6*epoch)\n",
    "\n",
    "def straight_stack(x, num_filters, rep = 3, weight_decay = 1e-4, dropout_start = 0.2, dropout_add = .1):\n",
    "    for n in range(rep):\n",
    "        x = Conv2D((2**n)*num_filters, (3,3), padding='same', activation='relu', kernel_regularizer=regularizers.l2(weight_decay))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Conv2D((2**n)*num_filters, (3,3), padding='same', activation='relu', kernel_regularizer=regularizers.l2(weight_decay))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = MaxPool2D()(x)\n",
    "        x = Dropout(dropout_start+n*dropout_add)(x)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 3, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "print(x_train.shape)\n",
    " \n",
    "#z-score\n",
    "mean = np.mean(x_train,axis=(0,1,2,3))\n",
    "std = np.std(x_train,axis=(0,1,2,3))\n",
    "x_train = (x_train-mean)/(std+1e-7)\n",
    "x_test = (x_test-mean)/(std+1e-7)\n",
    " \n",
    "num_classes = 10\n",
    "y_train = np_utils.to_categorical(y_train,num_classes)\n",
    "y_test = np_utils.to_categorical(y_test,num_classes)\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    )\n",
    "datagen.fit(x_train)\n",
    "\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 16, 16)\n",
      "GPU settings allow for inf layers\n",
      "Minimum output size allow for 6 layers\n",
      "Number of layers 2\n",
      "First Layer Size: 2 (Number of Units)\n",
      "First Layer Output Size: 2 (Number of Tensors)\n",
      "Final Layer Size 1\n",
      "('output shape of conv layers: ', TensorShape([Dimension(None), Dimension(16), Dimension(4), Dimension(4)]))\n",
      "5850\n",
      "number of parameters 5850\n",
      "Epoch 1/1\n",
      "781/781 [==============================] - 2903s 4s/step - loss: 1.9532 - acc: 0.2981 - val_loss: 1.6956 - val_acc: 0.3800\n",
      "10000/10000 [==============================] - 44s 4ms/step\n",
      "{4: (5850, [1.6624127925872803, 0.3934])}\n",
      "(4, 8, 8)\n",
      "GPU settings allow for inf layers\n",
      "Minimum output size allow for 4 layers\n",
      "Number of layers 1\n",
      "First Layer Size: 1 (Number of Units)\n",
      "First Layer Output Size: 1 (Number of Tensors)\n",
      "Final Layer Size 1\n",
      "('output shape of conv layers: ', TensorShape([Dimension(None), Dimension(16), Dimension(4), Dimension(4)]))\n",
      "5798\n",
      "number of parameters 5798\n",
      "Epoch 1/1\n",
      "781/781 [==============================] - 311s 399ms/step - loss: 1.9852 - acc: 0.2943 - val_loss: 1.6797 - val_acc: 0.3760\n",
      "10000/10000 [==============================] - 34s 3ms/step\n",
      "{2: (5798, [1.6725436157226563, 0.3969]), 4: (5850, [1.6624127925872803, 0.3934])}\n",
      "('output shape of conv layers: ', TensorShape([Dimension(None), Dimension(16), Dimension(4), Dimension(4)]))\n",
      "7646\n",
      "number of parameters 7646\n",
      "Epoch 1/1\n",
      "781/781 [==============================] - 214s 274ms/step - loss: 2.0551 - acc: 0.2787 - val_loss: 1.7006 - val_acc: 0.4000\n",
      "10000/10000 [==============================] - 23s 2ms/step\n",
      "{1: (7646, [1.6588449335098268, 0.3939]), 2: (5798, [1.6725436157226563, 0.3969]), 4: (5850, [1.6624127925872803, 0.3934])}\n"
     ]
    }
   ],
   "source": [
    "viewer = keras.callbacks.TensorBoard(log_dir='./logs', \n",
    "                                     histogram_freq=0, \n",
    "                                     batch_size=batch_size, \n",
    "                                     write_graph=True)\n",
    "num_filters = 4\n",
    "num_val_test = 500\n",
    "epochs = 1\n",
    "steps_per_epoch = x_train.shape[0] // batch_size\n",
    "model_details = {}\n",
    "conv_layers = 3\n",
    "for num_stack in [4,2,1]:\n",
    "    inputs = Input(shape=(3,32,32))\n",
    "    input_array = []\n",
    "    pyrm_layers = int(np.log2(num_stack))\n",
    "    for stack in range(num_stack):\n",
    "        x = straight_stack(inputs, num_filters/num_stack, rep = conv_layers - pyrm_layers)\n",
    "        input_array.append(x)\n",
    "    if pyrm_layers > 0:\n",
    "        input_size = tuple(input_array[0].shape[1:].as_list())\n",
    "        print(input_size)\n",
    "        x = weave.pyrm_net(inputs = input_array,\n",
    "                           n_layers = pyrm_layers,\n",
    "                           n_filters_start = input_size[0]*2,\n",
    "                           n_gpus = 1,\n",
    "                           r_filter = 4,\n",
    "                           r_combine= 2,\n",
    "                           min_dim = 2,\n",
    "                           max_pool_loc = 1,\n",
    "                           pure_combine = False)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = MaxPool2D()(x)\n",
    "    else:\n",
    "        pass\n",
    "    print(\"output shape of conv layers: \",x.shape)\n",
    "    x = Flatten()(x)\n",
    "    \n",
    "    predictions = Dense(num_classes, activation='softmax')(x)\n",
    "    model = Model(inputs=[inputs], outputs=predictions)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    #model.summary()\n",
    "    num_params = model.count_params()\n",
    "    print(num_params)\n",
    "    print('number of parameters %d' % num_params)\n",
    "    model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                    steps_per_epoch= steps_per_epoch,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test[0:num_val_test],y_test[0:num_val_test]),\n",
    "                    callbacks=[LearningRateScheduler(lr_schedule), viewer])\n",
    "    model_details[num_stack] = (num_params, model.evaluate(x_test,y_test))\n",
    "    print(model_details)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: (7646, [1.6588449335098268, 0.3939]),\n",
       " 2: (5798, [1.6725436157226563, 0.3969]),\n",
       " 4: (5850, [1.6624127925872803, 0.3934])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_details\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 3, 32, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 4, 32, 32)         112       \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 4, 32, 32)         128       \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 4, 32, 32)         148       \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 4, 32, 32)         128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 4, 16, 16)         0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 4, 16, 16)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 8, 16, 16)         296       \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 8, 16, 16)         64        \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 8, 16, 16)         584       \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 8, 16, 16)         64        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 8, 8, 8)           0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 8, 8, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 16, 8, 8)          1168      \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 16, 8, 8)          32        \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 16, 8, 8)          2320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 16, 8, 8)          32        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 16, 4, 4)          0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 16, 4, 4)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 7,646\n",
      "Trainable params: 7,422\n",
      "Non-trainable params: 224\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 16, 16)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "pyrm_net() got an unexpected keyword argument 'input_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-f70f4740702c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m                    \u001b[0mmax_pool_loc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                    \u001b[0mpure_combine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                    end_max_pool = False)\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"output shape of conv layers: \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: pyrm_net() got an unexpected keyword argument 'input_size'"
     ]
    }
   ],
   "source": [
    "num_filters = 32\n",
    "num_val_test = 500\n",
    "epochs = 65\n",
    "model_details = {}\n",
    "conv_layers = 3\n",
    "num_stack = 4\n",
    "inputs = Input(shape=(3,32,32))\n",
    "input_array = []\n",
    "pyrm_layers = 2\n",
    "for stack in range(num_stack):\n",
    "    x = straight_stack(inputs, num_filters/num_stack, rep = 1)\n",
    "    input_array.append(x)\n",
    "input_size = tuple(input_array[0].shape[1:].as_list())\n",
    "print(input_size)\n",
    "x = weave.pyrm_net(input_size=input_size,\n",
    "                   n_layers = pyrm_layers,\n",
    "                   n_filters_start = input_size[0]*2,\n",
    "                   n_gpus = 1,\n",
    "                   inputs = input_array,\n",
    "                   r_filter = 2,\n",
    "                   r_combine= 1,\n",
    "                   min_dim = 2,\n",
    "                   max_pool_loc = 2,\n",
    "                   pure_combine = True,\n",
    "                   end_max_pool = False)\n",
    "\n",
    "print(\"output shape of conv layers: \",x.shape)\n",
    "x = Flatten()(x)\n",
    "\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "model = Model(inputs=[inputs], outputs=predictions)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                steps_per_epoch=x_train.shape[0] // batch_size,\n",
    "                epochs=epochs,\n",
    "                verbose=1,\n",
    "                validation_data=(x_test[0:num_val_test],y_test[0:num_val_test]),\n",
    "                callbacks=[LearningRateScheduler(lr_schedule)])\n",
    "model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
