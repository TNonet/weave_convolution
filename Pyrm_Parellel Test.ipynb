{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization, Input\n",
    "from keras.layers import Conv2D, MaxPool2D\n",
    "from keras.models import Model\n",
    "from keras.datasets import cifar10\n",
    "from keras import regularizers\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "import numpy as np\n",
    "import weave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_schedule(epoch):\n",
    "    return (0.00100385 - 6.92308e-6*epoch)\n",
    "\n",
    "def straight_stack(x, num_filters, rep = 3, weight_decay = 1e-4, dropout_start = 0.2, dropout_add = .1):\n",
    "    for n in range(rep):\n",
    "        x = Conv2D((2**n)*num_filters, (3,3), padding='same', activation='elu', kernel_regularizer=regularizers.l2(weight_decay))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Conv2D((2**n)*num_filters, (3,3), padding='same', activation='elu', kernel_regularizer=regularizers.l2(weight_decay))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = MaxPool2D()(x)\n",
    "        x = Dropout(dropout_start+n*dropout_add)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 3, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "print(x_train.shape)\n",
    " \n",
    "#z-score\n",
    "mean = np.mean(x_train,axis=(0,1,2,3))\n",
    "std = np.std(x_train,axis=(0,1,2,3))\n",
    "x_train = (x_train-mean)/(std+1e-7)\n",
    "x_test = (x_test-mean)/(std+1e-7)\n",
    " \n",
    "num_classes = 10\n",
    "y_train = np_utils.to_categorical(y_train,num_classes)\n",
    "y_test = np_utils.to_categorical(y_test,num_classes)\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    )\n",
    "datagen.fit(x_train)\n",
    "\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "781/781 [==============================] - 436s 558ms/step - loss: 2.0201 - acc: 0.2863 - val_loss: 1.6055 - val_acc: 0.3960\n",
      "Epoch 2/2\n",
      "781/781 [==============================] - 436s 558ms/step - loss: 1.6341 - acc: 0.4045 - val_loss: 1.5147 - val_acc: 0.4420\n",
      "10000/10000 [==============================] - 50s 5ms/step\n",
      "{1: (7646, [1.4586845079421997, 0.4645])}\n",
      "GPU settings allow for inf layers\n",
      "Minimum output size allow for 5 layers\n",
      "Number of layers 1\n",
      "First Layer Size: 1 (Number of Units)\n",
      "('Disjoint:', True)\n",
      "number of units 1\n",
      "number of devices 2\n",
      "number of inputs 2\n",
      "First Layer Output Size: 1 (Number of Tensors)\n",
      "Final Layer Size 1\n",
      "Epoch 1/2\n",
      " 54/781 [=>............................] - ETA: 52:10 - loss: 1.9839 - acc: 0.2705"
     ]
    }
   ],
   "source": [
    "viewer = keras.callbacks.TensorBoard(log_dir='./logs', \n",
    "                                     histogram_freq=0, \n",
    "                                     batch_size=batch_size, \n",
    "                                     write_graph=True)\n",
    "num_filters = 4\n",
    "num_val_test = 500\n",
    "epochs = 2\n",
    "model_details = {}\n",
    "conv_layers = 3\n",
    "for num_stack in [1,2,4]:\n",
    "    inputs = Input(shape=(3,32,32))\n",
    "    input_array = []\n",
    "    pyrm_layers = int(np.log2(num_stack))\n",
    "    for stack in range(num_stack):\n",
    "        x = straight_stack(inputs, num_filters/num_stack, rep = conv_layers - pyrm_layers)\n",
    "        input_array.append(x)\n",
    "    if pyrm_layers > 0:\n",
    "        x = weave.pyrm_net(input_size=(4,4,128),\n",
    "                           n_layers = pyrm_layers,\n",
    "                           n_filters_start = 128,\n",
    "                           n_gpus = 1,\n",
    "                           inputs = input_array,\n",
    "                           r_filter = 1,\n",
    "                           r_combine= 1,\n",
    "                           min_dim = 2,\n",
    "                           max_pool_loc = 5,\n",
    "                           pure_combine = False,\n",
    "                           end_max_pool = False)\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    \n",
    "    predictions = Dense(num_classes, activation='softmax')(x)\n",
    "    model = Model(inputs=[inputs], outputs=predictions)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    #model.summary()\n",
    "    num_params = model.count_params()\n",
    "    \n",
    "    model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                    steps_per_epoch=x_train.shape[0] // batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test[0:num_val_test],y_test[0:num_val_test]),\n",
    "                    callbacks=[LearningRateScheduler(lr_schedule), viewer])\n",
    "    model_details[num_stack] = (num_params, model.evaluate(x_test,y_test))\n",
    "    print(model_details)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_details\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
