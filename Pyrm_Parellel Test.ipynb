{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization, Input\n",
    "from keras.layers import Conv2D, MaxPool2D\n",
    "from keras.models import Model\n",
    "from keras.datasets import cifar10\n",
    "from keras import regularizers\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "import numpy as np\n",
    "import weave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_schedule(epoch):\n",
    "    return (0.00100 - 7e-6*epoch)\n",
    "\n",
    "def straight_stack(x, num_filters, rep = 3, weight_decay = 1e-4, dropout_start = 0.2, dropout_add = .1):\n",
    "    for n in range(rep):\n",
    "        x = Conv2D((2**n)*num_filters, (3,3), padding='same', activation='relu', kernel_regularizer=regularizers.l2(weight_decay))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Conv2D((2**n)*num_filters, (3,3), padding='same', activation='relu', kernel_regularizer=regularizers.l2(weight_decay))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = MaxPool2D()(x)\n",
    "        x = Dropout(dropout_start+n*dropout_add)(x)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 3, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "print(x_train.shape)\n",
    " \n",
    "#z-score\n",
    "mean = np.mean(x_train,axis=(0,1,2,3))\n",
    "std = np.std(x_train,axis=(0,1,2,3))\n",
    "x_train = (x_train-mean)/(std+1e-7)\n",
    "x_test = (x_test-mean)/(std+1e-7)\n",
    " \n",
    "num_classes = 10\n",
    "y_train = np_utils.to_categorical(y_train,num_classes)\n",
    "y_test = np_utils.to_categorical(y_test,num_classes)\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    )\n",
    "datagen.fit(x_train)\n",
    "\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 16, 16)\n",
      "GPU settings allow for inf layers\n",
      "Minimum output size allow for 6 layers\n",
      "Number of layers 2\n",
      "First Layer Size: 2 (Number of Units)\n",
      "('Disjoint:', True)\n",
      "number of units 2\n",
      "number of devices 4\n",
      "number of inputs 4\n",
      "First Layer Output Size: 2 (Number of Tensors)\n",
      "('Disjoint:', True)\n",
      "number of units 1\n",
      "number of devices 4\n",
      "number of inputs 2\n",
      "Final Layer Size 1\n",
      "('output shape of conv layers: ', TensorShape([Dimension(None), Dimension(4), Dimension(16), Dimension(16)]))\n",
      "('number of parameters %d', 11558)\n",
      "Epoch 1/15\n",
      "781/781 [==============================] - 545s 697ms/step - loss: 1.8736 - acc: 0.3159 - val_loss: 1.6509 - val_acc: 0.4280\n",
      "Epoch 2/15\n",
      "781/781 [==============================] - 540s 692ms/step - loss: 1.6818 - acc: 0.3855 - val_loss: 1.6091 - val_acc: 0.4100\n",
      "Epoch 3/15\n",
      "781/781 [==============================] - 526s 673ms/step - loss: 1.6249 - acc: 0.4080 - val_loss: 1.6348 - val_acc: 0.4180\n",
      "Epoch 4/15\n",
      "781/781 [==============================] - 525s 672ms/step - loss: 1.5829 - acc: 0.4253 - val_loss: 1.6283 - val_acc: 0.4200\n",
      "Epoch 5/15\n",
      "781/781 [==============================] - 527s 674ms/step - loss: 1.5557 - acc: 0.4362 - val_loss: 1.5913 - val_acc: 0.4400\n",
      "Epoch 6/15\n",
      "781/781 [==============================] - 530s 679ms/step - loss: 1.5354 - acc: 0.4462 - val_loss: 1.5990 - val_acc: 0.4340\n",
      "Epoch 7/15\n",
      "781/781 [==============================] - 525s 672ms/step - loss: 1.5166 - acc: 0.4493 - val_loss: 1.5909 - val_acc: 0.4380\n",
      "Epoch 8/15\n",
      "781/781 [==============================] - 524s 671ms/step - loss: 1.4995 - acc: 0.4568 - val_loss: 1.6524 - val_acc: 0.4360\n",
      "Epoch 9/15\n",
      "781/781 [==============================] - 525s 672ms/step - loss: 1.4878 - acc: 0.4614 - val_loss: 1.5583 - val_acc: 0.4460\n",
      "Epoch 10/15\n",
      "781/781 [==============================] - 524s 671ms/step - loss: 1.4749 - acc: 0.4647 - val_loss: 1.5475 - val_acc: 0.4400\n",
      "Epoch 11/15\n",
      "781/781 [==============================] - 524s 671ms/step - loss: 1.4686 - acc: 0.4679 - val_loss: 1.6218 - val_acc: 0.4420\n",
      "Epoch 12/15\n",
      "781/781 [==============================] - 526s 674ms/step - loss: 1.4631 - acc: 0.4711 - val_loss: 1.6274 - val_acc: 0.4280\n",
      "Epoch 13/15\n",
      "781/781 [==============================] - 526s 674ms/step - loss: 1.4504 - acc: 0.4746 - val_loss: 1.5934 - val_acc: 0.4220\n",
      "Epoch 14/15\n",
      "781/781 [==============================] - 525s 672ms/step - loss: 1.4441 - acc: 0.4777 - val_loss: 1.5163 - val_acc: 0.4520\n",
      "Epoch 15/15\n",
      "781/781 [==============================] - 524s 671ms/step - loss: 1.4354 - acc: 0.4815 - val_loss: 1.5898 - val_acc: 0.4320\n",
      "10000/10000 [==============================] - 46s 5ms/step\n",
      "{4: (11558, [1.5121799570083618, 0.4648])}\n",
      "(4, 8, 8)\n",
      "GPU settings allow for inf layers\n",
      "Minimum output size allow for 4 layers\n",
      "Number of layers 1\n",
      "First Layer Size: 1 (Number of Units)\n",
      "('Disjoint:', True)\n",
      "number of units 1\n",
      "number of devices 2\n",
      "number of inputs 2\n",
      "First Layer Output Size: 1 (Number of Tensors)\n",
      "Final Layer Size 1\n",
      "('output shape of conv layers: ', TensorShape([Dimension(None), Dimension(8), Dimension(8), Dimension(8)]))\n",
      "('number of parameters %d', 6830)\n",
      "Epoch 1/15\n",
      "781/781 [==============================] - 426s 546ms/step - loss: 1.8899 - acc: 0.3038 - val_loss: 1.5916 - val_acc: 0.4080\n",
      "Epoch 2/15\n",
      "781/781 [==============================] - 424s 543ms/step - loss: 1.6168 - acc: 0.4090 - val_loss: 1.4836 - val_acc: 0.4380\n",
      "Epoch 3/15\n",
      "781/781 [==============================] - 425s 544ms/step - loss: 1.5309 - acc: 0.4412 - val_loss: 1.4328 - val_acc: 0.4720\n",
      "Epoch 4/15\n",
      "781/781 [==============================] - 425s 544ms/step - loss: 1.4747 - acc: 0.4627 - val_loss: 1.3517 - val_acc: 0.5120\n",
      "Epoch 5/15\n",
      "781/781 [==============================] - 423s 542ms/step - loss: 1.4393 - acc: 0.4795 - val_loss: 1.3299 - val_acc: 0.5180\n",
      "Epoch 6/15\n",
      "781/781 [==============================] - 423s 542ms/step - loss: 1.4206 - acc: 0.4876 - val_loss: 1.2913 - val_acc: 0.5320\n",
      "Epoch 7/15\n",
      "781/781 [==============================] - 424s 543ms/step - loss: 1.3940 - acc: 0.4947 - val_loss: 1.3210 - val_acc: 0.5180\n",
      "Epoch 8/15\n",
      "781/781 [==============================] - 424s 542ms/step - loss: 1.3806 - acc: 0.5003 - val_loss: 1.2772 - val_acc: 0.5660\n",
      "Epoch 9/15\n",
      "781/781 [==============================] - 426s 546ms/step - loss: 1.3663 - acc: 0.5082 - val_loss: 1.3211 - val_acc: 0.5220\n",
      "Epoch 10/15\n",
      "781/781 [==============================] - 422s 541ms/step - loss: 1.3579 - acc: 0.5111 - val_loss: 1.3386 - val_acc: 0.5260\n",
      "Epoch 11/15\n",
      "781/781 [==============================] - 422s 540ms/step - loss: 1.3407 - acc: 0.5172 - val_loss: 1.3110 - val_acc: 0.5360\n",
      "Epoch 12/15\n",
      "781/781 [==============================] - 423s 541ms/step - loss: 1.3343 - acc: 0.5193 - val_loss: 1.3299 - val_acc: 0.5320\n",
      "Epoch 13/15\n",
      "781/781 [==============================] - 432s 554ms/step - loss: 1.3283 - acc: 0.5246 - val_loss: 1.3637 - val_acc: 0.5100\n",
      "Epoch 14/15\n",
      "781/781 [==============================] - 435s 557ms/step - loss: 1.3152 - acc: 0.5255 - val_loss: 1.3104 - val_acc: 0.5220\n",
      "Epoch 15/15\n",
      "781/781 [==============================] - 429s 549ms/step - loss: 1.3151 - acc: 0.5293 - val_loss: 1.2841 - val_acc: 0.5260\n",
      "10000/10000 [==============================] - 45s 4ms/step\n",
      "{2: (6830, [1.3042584678649902, 0.5394]), 4: (11558, [1.5121799570083618, 0.4648])}\n",
      "('output shape of conv layers: ', TensorShape([Dimension(None), Dimension(16), Dimension(4), Dimension(4)]))\n",
      "('number of parameters %d', 7646)\n",
      "Epoch 1/15\n",
      "781/781 [==============================] - 414s 531ms/step - loss: 2.1950 - acc: 0.2500 - val_loss: 1.6892 - val_acc: 0.3780\n",
      "Epoch 2/15\n",
      "781/781 [==============================] - 412s 528ms/step - loss: 1.7045 - acc: 0.3743 - val_loss: 1.5592 - val_acc: 0.4160\n",
      "Epoch 3/15\n",
      "781/781 [==============================] - 412s 528ms/step - loss: 1.6120 - acc: 0.4127 - val_loss: 1.4819 - val_acc: 0.4660\n",
      "Epoch 4/15\n",
      "781/781 [==============================] - 413s 528ms/step - loss: 1.5535 - acc: 0.4348 - val_loss: 1.4504 - val_acc: 0.4840\n",
      "Epoch 5/15\n",
      "781/781 [==============================] - 414s 530ms/step - loss: 1.5078 - acc: 0.4531 - val_loss: 1.4309 - val_acc: 0.4840\n",
      "Epoch 6/15\n",
      "781/781 [==============================] - 414s 530ms/step - loss: 1.4731 - acc: 0.4670 - val_loss: 1.3814 - val_acc: 0.4980\n",
      "Epoch 7/15\n",
      "781/781 [==============================] - 414s 530ms/step - loss: 1.4382 - acc: 0.4769 - val_loss: 1.4252 - val_acc: 0.5060\n",
      "Epoch 8/15\n",
      "781/781 [==============================] - 414s 530ms/step - loss: 1.4235 - acc: 0.4852 - val_loss: 1.3277 - val_acc: 0.5160\n",
      "Epoch 9/15\n",
      "781/781 [==============================] - 413s 529ms/step - loss: 1.3962 - acc: 0.4978 - val_loss: 1.3296 - val_acc: 0.5160\n",
      "Epoch 10/15\n",
      "781/781 [==============================] - 413s 529ms/step - loss: 1.3782 - acc: 0.5057 - val_loss: 1.3439 - val_acc: 0.5080\n",
      "Epoch 11/15\n",
      "781/781 [==============================] - 413s 529ms/step - loss: 1.3688 - acc: 0.5071 - val_loss: 1.2646 - val_acc: 0.5500\n",
      "Epoch 12/15\n",
      "781/781 [==============================] - 414s 530ms/step - loss: 1.3559 - acc: 0.5125 - val_loss: 1.2247 - val_acc: 0.5640\n",
      "Epoch 13/15\n",
      "781/781 [==============================] - 414s 530ms/step - loss: 1.3371 - acc: 0.5205 - val_loss: 1.3907 - val_acc: 0.5340\n",
      "Epoch 14/15\n",
      "781/781 [==============================] - 416s 533ms/step - loss: 1.3280 - acc: 0.5246 - val_loss: 1.3281 - val_acc: 0.5200\n",
      "Epoch 15/15\n",
      "781/781 [==============================] - 413s 529ms/step - loss: 1.3177 - acc: 0.5294 - val_loss: 1.2735 - val_acc: 0.5360\n",
      "10000/10000 [==============================] - 45s 4ms/step\n",
      "{1: (7646, [1.290688921546936, 0.545]), 2: (6830, [1.3042584678649902, 0.5394]), 4: (11558, [1.5121799570083618, 0.4648])}\n"
     ]
    }
   ],
   "source": [
    "viewer = keras.callbacks.TensorBoard(log_dir='./logs', \n",
    "                                     histogram_freq=0, \n",
    "                                     batch_size=batch_size, \n",
    "                                     write_graph=True)\n",
    "num_filters = 4\n",
    "num_val_test = 500\n",
    "epochs = 15\n",
    "model_details = {}\n",
    "conv_layers = 3\n",
    "for num_stack in [4,2,1]:\n",
    "    inputs = Input(shape=(3,32,32))\n",
    "    input_array = []\n",
    "    pyrm_layers = int(np.log2(num_stack))\n",
    "    for stack in range(num_stack):\n",
    "        x = straight_stack(inputs, num_filters/num_stack, rep = conv_layers - pyrm_layers)\n",
    "        input_array.append(x)\n",
    "    if pyrm_layers > 0:\n",
    "        input_size = tuple(input_array[0].shape[1:].as_list())\n",
    "        print(input_size)\n",
    "        x = weave.pyrm_net(input_size=input_size,\n",
    "                           n_layers = pyrm_layers,\n",
    "                           n_filters_start = input_size[0]*2,\n",
    "                           n_gpus = 1,\n",
    "                           inputs = input_array,\n",
    "                           r_filter = 2,\n",
    "                           r_combine= 1,\n",
    "                           min_dim = 2,\n",
    "                           max_pool_loc = 2,\n",
    "                           pure_combine = True,\n",
    "                           end_max_pool = False)\n",
    "    else:\n",
    "        pass\n",
    "    print(\"output shape of conv layers: \",x.shape)\n",
    "    x = Flatten()(x)\n",
    "    \n",
    "    predictions = Dense(num_classes, activation='softmax')(x)\n",
    "    model = Model(inputs=[inputs], outputs=predictions)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    #model.summary()\n",
    "    num_params = model.count_params()\n",
    "    print('number of parameters %d', num_params)\n",
    "    model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                    steps_per_epoch=x_train.shape[0] // batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test[0:num_val_test],y_test[0:num_val_test]),\n",
    "                    callbacks=[LearningRateScheduler(lr_schedule), viewer])\n",
    "    model_details[num_stack] = (num_params, model.evaluate(x_test,y_test))\n",
    "    print(model_details)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: (7646, [1.290688921546936, 0.545]),\n",
       " 2: (6830, [1.3042584678649902, 0.5394]),\n",
       " 4: (11558, [1.5121799570083618, 0.4648])}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_details\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 16, 16)\n",
      "GPU settings allow for inf layers\n",
      "Minimum output size allow for 3 layers\n",
      "Number of layers 2\n",
      "First Layer Size: 2 (Number of Units)\n",
      "('Disjoint:', True)\n",
      "number of units 2\n",
      "number of devices 4\n",
      "number of inputs 4\n",
      "First Layer Output Size: 2 (Number of Tensors)\n",
      "('Disjoint:', True)\n",
      "number of units 1\n",
      "number of devices 4\n",
      "number of inputs 2\n",
      "Final Layer Size 1\n",
      "('output shape of conv layers: ', TensorShape([Dimension(None), Dimension(32), Dimension(8), Dimension(8)]))\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 3, 32, 32)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 8, 32, 32)    224         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 8, 32, 32)    224         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 8, 32, 32)    224         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 8, 32, 32)    224         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 8, 32, 32)    128         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 8, 32, 32)    128         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 8, 32, 32)    128         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 8, 32, 32)    128         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 8, 32, 32)    584         batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 8, 32, 32)    584         batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 8, 32, 32)    584         batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 8, 32, 32)    584         batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 8, 32, 32)    128         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 8, 32, 32)    128         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 8, 32, 32)    128         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 8, 32, 32)    128         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling2D) (None, 8, 16, 16)    0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling2D) (None, 8, 16, 16)    0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling2D) (None, 8, 16, 16)    0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling2D) (None, 8, 16, 16)    0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 8, 16, 16)    0           max_pooling2d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 8, 16, 16)    0           max_pooling2d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 8, 16, 16)    0           max_pooling2d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 8, 16, 16)    0           max_pooling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "array_weave_6 (ArrayWeave)      (None, 8, 46, 46)    0           dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "zero_weave_6 (ZeroWeave)        (None, 8, 46, 46)    0           dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "array_weave_5 (ArrayWeave)      (None, 8, 46, 46)    0           dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "zero_weave_5 (ZeroWeave)        (None, 8, 46, 46)    0           dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 8, 46, 46)    0           array_weave_6[0][0]              \n",
      "                                                                 zero_weave_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 8, 46, 46)    0           array_weave_5[0][0]              \n",
      "                                                                 zero_weave_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_6 (ZeroPadding2D (None, 8, 48, 48)    0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_5 (ZeroPadding2D (None, 8, 48, 48)    0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 16, 16, 16)   1168        zero_padding2d_6[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 16, 16, 16)   1168        zero_padding2d_5[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling2D) (None, 16, 8, 8)     0           conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling2D) (None, 16, 8, 8)     0           conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 16, 8, 8)     64          max_pooling2d_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 16, 8, 8)     64          max_pooling2d_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, 16, 8, 8)     0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 16, 8, 8)     0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "array_weave_7 (ArrayWeave)      (None, 16, 22, 22)   0           dropout_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "zero_weave_7 (ZeroWeave)        (None, 16, 22, 22)   0           dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 16, 22, 22)   0           array_weave_7[0][0]              \n",
      "                                                                 zero_weave_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_7 (ZeroPadding2D (None, 16, 24, 24)   0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 32, 8, 8)     4640        zero_padding2d_7[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 2048)         0           conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 10)           20490       flatten_4[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 31,850\n",
      "Trainable params: 31,274\n",
      "Non-trainable params: 576\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "num_filters = 32\n",
    "num_val_test = 500\n",
    "epochs = 65\n",
    "model_details = {}\n",
    "conv_layers = 3\n",
    "num_stack = 4\n",
    "inputs = Input(shape=(3,32,32))\n",
    "input_array = []\n",
    "pyrm_layers = 2\n",
    "for stack in range(num_stack):\n",
    "    x = straight_stack(inputs, num_filters/num_stack, rep = 1)\n",
    "    input_array.append(x)\n",
    "input_size = tuple(input_array[0].shape[1:].as_list())\n",
    "print(input_size)\n",
    "x = weave.pyrm_net(input_size=input_size,\n",
    "                   n_layers = pyrm_layers,\n",
    "                   n_filters_start = input_size[0]*2,\n",
    "                   n_gpus = 1,\n",
    "                   inputs = input_array,\n",
    "                   r_filter = 2,\n",
    "                   r_combine= 1,\n",
    "                   min_dim = 2,\n",
    "                   max_pool_loc = 1,\n",
    "                   pure_combine = True,\n",
    "                   end_max_pool = False)\n",
    "\n",
    "print(\"output shape of conv layers: \",x.shape)\n",
    "x = Flatten()(x)\n",
    "\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "model = Model(inputs=[inputs], outputs=predictions)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/65\n",
      "378/781 [=============>................] - ETA: 24:31 - loss: 1.7438 - acc: 0.3702"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-2102f8dd73be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                 \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnum_val_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnum_val_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                 callbacks=[LearningRateScheduler(lr_schedule)])\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Takn/anaconda2/lib/python2.7/site-packages/keras/legacy/interfaces.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Takn/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1413\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1414\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1415\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Takn/anaconda2/lib/python2.7/site-packages/keras/engine/training_generator.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    211\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    212\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Takn/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1213\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1214\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1215\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1216\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Takn/anaconda2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2664\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2666\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2667\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Takn/anaconda2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m                                 session)\n\u001b[0;32m-> 2636\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Takn/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                steps_per_epoch=x_train.shape[0] // batch_size,\n",
    "                epochs=epochs,\n",
    "                verbose=1,\n",
    "                validation_data=(x_test[0:num_val_test],y_test[0:num_val_test]),\n",
    "                callbacks=[LearningRateScheduler(lr_schedule)])\n",
    "model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
